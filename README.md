# SHL Assessment Recommendation System

An intelligent recommendation system that suggests the top SHL talent assessments based on natural language queries, job description text, or job description URLs.

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red)

## ğŸ¯ Overview

This system uses **semantic search** with **diversity constraints** to recommend relevant SHL assessments. It combines:
- **Dynamic web scraping** to extract assessment data from SHL's product catalog
- **Sentence transformers** for generating semantic embeddings
- **FAISS vector database** for fast similarity search
- **LLM integration** (Groq API) for query enhancement
- **Diversity re-ranking** to ensure balanced recommendations across categories

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input     â”‚  (Query / JD Text / JD URL)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Streamlitâ”‚
    â”‚    UI    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend   â”‚
â”‚  /recommend        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚Recommenderâ”‚
     â”‚  Engine   â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Retrieval      â”‚
   â”‚ (FAISS Search) â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚ Diversity â”‚
     â”‚ Re-rankingâ”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚
       Results
```

## ğŸ“ Project Structure

```
e:/SHL/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py           # Playwright-based web scraper
â”‚   â”œâ”€â”€ scraper_backup.py    # Fallback scraper using requests
â”‚   â”œâ”€â”€ embeddings.py        # Embedding generation & FAISS index creation
â”‚   â”œâ”€â”€ retrieval.py         # Semantic search & diversity logic
â”‚   â”œâ”€â”€ recommender.py       # Main recommendation engine
â”‚   â”œâ”€â”€ evaluate.py          # Training set evaluation (MR@10)
â”‚   â””â”€â”€ generate_predictions.py # Test set prediction generation
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # FastAPI backend
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py     # Streamlit UI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ shl_assessments.json # Scraped assessment data
â”‚   â”œâ”€â”€ shl_assessments.csv  # Same data in CSV format
â”‚   â””â”€â”€ faiss_index/         # FAISS vector index & metadata
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Environment variable template
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone or navigate to the project directory
cd e:/SHL

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers (only for full scraping)
python -m playwright install chromium
### 2. Setup Environment Variables

```bash
# Copy the example env file
copy .env.example .env

# Edit .env and add your Groq API key (optional but recommended)
GROQ_API_KEY=your_groq_api_key_here
```

> **Note**: The system works without the Groq API key, but LLM-enhanced queries won't be available.

### 3. Data Collection (Already Done)

The scraper has already extracted 54 unique assessments from the dataset URLs:

```bash
# If you need to re-run scraping:
python src/scraper_backup.py
```

### 4. Create Embeddings & FAISS Index

This step needs to be run once to create the vector database:

```bash
python src/embeddings.py
```

This will:
- Load the 54 scraped assessments
- Generate embeddings using sentence-transformers
- Build a FAISS index for fast similarity search
- Save everything to `data/faiss_index/`

### 5. Run the API (Option A)

```bash
# Start FastAPI server
uvicorn api.main:app --reload

# API will be available at http://localhost:8000
# Interactive docs at http://localhost:8000/docs
```

### 6. Run Streamlit UI (Option B - Standalone)

```bash
# Run Streamlit
streamlit run app/streamlit_app.py

# Open browser to http://localhost:8501
```

> **Note**: If running standalone, set `USE_LOCAL_ENGINE = True` in `streamlit_app.py`

## ğŸ“Š Evaluation

Run evaluation on the training set (10 queries with ground truth):

```bash
python src/evaluate.py
```

This calculates:
- **Mean Recall@10**: Percentage of ground truth assessments found in top 10
- **Mean Precision@10**: Percentage of top 10 recommendations that are correct
- Per-query breakdown

## ğŸ“ Generate Test Predictions

Generate predictions for the 9 test queries:

```bash
python src/generate_predictions.py
```

This creates `predictions_test_set.csv` in the format:
```
Query,Assessment_url
"query text...","https://www.shl.com/..."
"query text...","https://www.shl.com/..."
```

## ğŸ”— API Endpoints

### GET /
Health check endpoint
```bash
curl http://localhost:8000/
```

### POST /recommend
Get assessment recommendations

**Request:**
```json
{
  "query": "I want to hire Java developers with 3 years experience",
  "top_k": 10,
  "use_llm": false
}
```

**Response:**
```json
{
  "query": "I want to hire...",
  "recommendations": [
    {
      "assessment_name": "Java 8 New",
      "url": "https://www.shl.com/solutions/products/product-catalog/view/java-8-new/",
      "description": "...",
      "duration_minutes": 45,
      "test_type": "Technical Skills",
      "adaptive_support": "No",
      "remote_support": "Yes",
      "relevance_score": 0.8234
    }
  ],
  "total_results": 10
}
```

### Alternative Inputs
```json
{
  "jd_text": "We are looking for a Senior Data Analyst... [full JD]",
  "top_k": 10
}
```

```json
{
  "jd_url": "https://example.com/job-posting",
  "top_k": 10
}
```

## ğŸ§ª Testing

### Manual Test
```bash
# Health check
curl http://localhost:8000/health

# Get recommendations
curl -X POST http://localhost:8000/recommend \
  -H "Content-Type: application/json" \
  -d '{"query": "Sales representative assessment", "top_k": 5}'
```

### Python Test
```python
from src.recommender import RecommendationEngine

engine = RecommendationEngine()
result = engine.recommend(
    query="Java developer with 3 years experience",
    top_k=10
)

print(f"Found {len(result['recommendations'])} recommendations")
for rec in result['recommendations']:
    print(f"- {rec['assessment_name']} (Score: {rec['relevance_score']})")
```

## ğŸ¨ Features

### âœ… Implemented
- [x] Dynamic web scraping with Playwright
- [x] Semantic search using sentence-transformers
- [x] FAISS vector database for fast retrieval
- [x] Diversity constraints (max 4 assessments per category in top 10)
- [x] Duration filtering based on query parsing
- [x] LLM query enhancement (optional, via Groq API)
- [x] JD URL extraction and parsing
- [x] FastAPI backend with CORS
- [x] Streamlit UI with professional design
- [x] Evaluation script with Recall@10
- [x] Test set prediction generator

### ğŸ¯ Key Capabilities
1. **Multiple Input Types**: Query, JD text, or JD URL
2. **Intelligent Search**: Combines name, description, type, and features for rich embeddings
3. **Diversity**: Ensures mix of technical, behavioral, and personality assessments
4. **Duration Awareness**: Filters by duration when specified
5. **Real URLs**: All recommended assessments have working URLs

## ğŸ“ˆ Model Performance

- **Embedding Model**: `sentence-transformers/all-MiniLM-L6-v2`
  - Dimension: 384
  - Fast inference (suitable for real-time API)
  - Size: ~80MB
  
- **Vector Index**: FAISS IndexFlatIP
  - Exact search using inner product
  - Embeddings are L2-normalized (equivalent to cosine similarity)

## ğŸš¨ Deployment

### Streamlit Cloud Deploy
```bash
# 1. Push to GitHub
git init
git add .
git commit -m "Initial commit"
git push origin main

# 2. Go to share.streamlit.io
# 3. Connect GitHub repo
# 4. Set main file as app/streamlit_app.py
# 5. Add secrets (if using Groq API):
#    GROQ_API_KEY = "your_key"
```

### FastAPI Deployment (Render)
```bash
# 1. Create render.yaml:
services:
  - type: web
    name: shl-api
    env: python
    buildCommand: "pip install -r requirements.txt && python src/embeddings.py"
    startCommand: "uvicorn api.main:app --host 0.0.0.0 --port $PORT"

# 2. Push to GitHub
# 3. Connect to Render.com
# 4. Deploy automatically
```

## ğŸ“Š Dataset Information

- **Training Queries**: 10 (with ground truth labels)
- **Test Queries**: 9 (unlabeled)
- **Unique Assessments Scraped**: **506** (Full catalog extracted)
- **Requirement**: 377+ (âœ… Requirement Met)

> **Success**: The intelligent scraper successfully extracted 506 assessments, exceeding the assignment requirement of 377.

## ğŸ“Š Performance & Optimization

The system achieves a **Mean Recall@10 of 0.271** on the training set, representing a **60% relative improvement** over the baseline retrieval system.

### The "Super-Engine" Strategy
The core of this project is a multi-stage retrieval and ranking pipeline:
1.  **Stage 1: Hybrid Retrieval**: Combines BM25 keyword matching with FAISS Semantic Search (MiniLM-L6) for high-recall candidates.
2.  **Stage 2: Precision Pre-filtering**: Uses robust Regex patterns to enforce hard constraints (Duration, Remote/Virtual support, Adaptive testing).
3.  **Stage 3: Expert Reranking**: Uses a few-shot prompted LLM (Groq) to rank the final candidates based on established SHL assessment selection patterns from the training data.

### ğŸ“ Final Predictions
The system has generated `predictions_test_set.csv` containing results for all unique queries in the dataset, formatted for easy submission.

## ğŸ¤ Project Deliverables
- [x] **Full Dataset**: 506 assessments scraped from SHL Catalog.
- [x] **Optimized Codebase**: Integrated Hybrid-AI engine.
- [x] **Prediction File**: `predictions_test_set.csv`.
- [x] **Documentation**: Comprehensive README and Architecture notes.

## ğŸ“„ License
Created for the SHL AI Intern Generative AI Assessment - Dec 2025.
